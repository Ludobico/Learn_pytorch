{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM 셀 구현\n",
    "지금까지 RNN을 살펴보았다면 이제 LSTM 셀과 LSTM 계층을 살펴보겠습니다. 이번 예제에서 사용할 데이터셋은 MNIST입니다.\n",
    "\n",
    "MNIST는 손으로 쓴 숫자 이미지(0~9까지 값을 갖는 고정 크기 이미지 (28px x 28px))들로 구성되어 있습니다.\n",
    "\n",
    "먼저 필요한 라이브러리들을 호출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dataset\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter # 파라미터 목록을 가지고 있는 라이브러리\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "torch.manual_seed(125)\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터에 대한 전처리를 합니다. 평균과 표준편차에 맞게 데이터를 정규화하기 위한 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_fransform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5),(1.0)) # 평균을 0.5, 표준편차를 1.0으로 데이터 정규화\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torchvision.datasets` 에서 제공하는 데이터셋 중 MNIST 데이터셋을 내려받습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST_DATASET\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:00<00:00, 19395944.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_DATASET\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./MNIST_DATASET\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST_DATASET\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 9663796.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_DATASET\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./MNIST_DATASET\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST_DATASET\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 6983886.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_DATASET\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./MNIST_DATASET\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST_DATASET\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_DATASET\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./MNIST_DATASET\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_dataset = dataset.MNIST(root='./MNIST_DATASET', transform=mnist_fransform, train=True, download=True)\n",
    "validation_dataset = dataset.MNIST(\n",
    "    root='./MNIST_DATASET', transform=mnist_fransform, train=False, download=True)\n",
    "\n",
    "test_dataset = dataset.MNIST(\n",
    "    root='./MNIST_DATASET', transform=mnist_fransform, train=False, download=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MNIST 데이터셋을 내려받기 위해 필요한 파라미터는 다음과 같습니다.\n",
    "\n",
    "```py\n",
    "train_dataset = dataset.MNIST(root='./MNIST_DATASET', transform=mnist_fransform, train=True, download=True)\n",
    "```\n",
    "\n",
    "* `root` : MNIST를 내려받을 위치 지정\n",
    "* `transform` : 앞에서 정의했던 데이터 전처리 적용\n",
    "* `train` : `True`로 설정할 경우 훈련용 데이터셋을 가져오지만, `False`로 설정할 경우 테스트용 데이터셋을 가져옵니다.\n",
    "* `download` : `True`로 설정될 경우 내려받으려는 위치에 MNIST 파일이 없으면 내려받지만 파일이 있다면 내려받지 않습니다.\n",
    "\n",
    "`dataloader`를 이용하여 내려받은 MNIST 파일을 메모리로 불러옵니다. 단, train_loader, valid_loader, test_loader 가 호출될 때 메모리로 불러온다는 점에 주의하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "valid_loader = DataLoader(\n",
    "    dataset=validation_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배치 크기 및 에포크 등 변수에 대한 값을 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "n_iters = 6000\n",
    "num_epoch = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epoch = int(num_epoch)\n",
    "\n",
    "print(num_epoch)\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM 셀에 대한 네트워크를 구축합니다. 모델의 전반적인 네트워크가 아닌 LSTM 셀에 집중한 네트워크입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMcell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(LSTMcell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        self.x2h = nn.Linear(input_size, 4 * hidden_size, bias=bias)\n",
    "        self.h2h = nn.Linear(input_size, 4 * hidden_size, bias=bias)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self): # 모델의 파라미터 초기화\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "    \n",
    "    def forward(self, x, hidden):\n",
    "        hx, cx = hidden\n",
    "        x = x.view(-1, x.size(1))\n",
    "\n",
    "        gates = self.x2h(x) + self.h2h(hx)\n",
    "        gates = gates.squeeze()\n",
    "        ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n",
    "\n",
    "        ingate = F.sigmoid(ingate) # 입력게이트에 시그모이드 활성화 함수 적용\n",
    "        forgetgate = F.sigmoid(forgetgate) # 망각 게이트에 시그모이드 활성화 함수 적용\n",
    "        cellgate = F.tanh(cellgate) # 셀 게이트에 하이퍼볼릭 탄젠트 활성화 함수 적용\n",
    "        outgate = F.sigmoid(outgate) # 출력 게이트에 시그모이드 활성화 함수 적용\n",
    "\n",
    "        cy = torch.mul(cx, forgetgate) + torch.mul(ingate, cellgate)\n",
    "        hy = torch.mul(outgate, F.tanh(cy))\n",
    "        return(hy, cy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "self.x2h = nn.Linear(input_size, 4 * hidden_size, bias=bias)\n",
    "```\n",
    "```py\n",
    "self.h2h = nn.Linear(input_size, 4 * hidden_size, bias=bias)\n",
    "```\n",
    "\n",
    "에서 `4 * hidden_size`가 사용되고 있는 이유에 대해 생각해 볼 필요가 있습니다. 왜 은닉층의 뉴런/유닛에 4를 곱할까요?\n",
    "\n",
    "그 답을 알기 위해서는 다음 그림을 먼저 이해해야 합니다.\n",
    "\n",
    "![](../Static/403_1.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9ba10514d92c171690b73ca0a9c097f69f78d6fa5f41507cb6917f0a9599880a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
