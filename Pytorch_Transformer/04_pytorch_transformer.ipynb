{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, num_tokens, dim_model, num_heads, num_encoder_layers, num_decoder_layers, dropout_p):\n",
    "        super().__init__()\n",
    "\n",
    "        self.transformer = nn.Transformer(d_model = dim_model, nhead = num_heads, num_encoder = num_encoder_layers, num_decoder = num_decoder_layers, dropout = dropout_p)\n",
    "\n",
    "    def forward(self):\n",
    "        pass"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.Transforemr 의 주요파라미터\n",
    "\n",
    "* d_model : 트랜스포머의 인코더와 디코더에서 정해진 입력과 출력의 크기를 의미 (default = 512)\n",
    "\n",
    "* num_encoder_layers : 인코더가 총 몇 층으로 구성되었는지를 의미. (default = 6)\n",
    "\n",
    "* num_decoder_layes : 디코더가 총 몇 층으로 구성되었는지를 의미. (default = 6)\n",
    "\n",
    "* nhead : 멀티헤드 어텐션 모델의 헤드 수 (default = 8)\n",
    "\n",
    "* dim_feedforward : FFNN 은닉층의 크기(default = 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, dim_model, dropout_p, max_len):\n",
    "        super().__init__()\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "        pos_encoding = torch.zeros(max_len, dim_model)\n",
    "        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1)\n",
    "        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model)\n",
    "\n",
    "        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n",
    "        pos_encoding[:, 0::1] = torch.cos(positions_list * division_term)\n",
    "\n",
    "        pos_encoding = pos_encoding.unsqueeze(0).transpose(0,1)\n",
    "    \n",
    "    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n",
    "        return self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
